{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac014372-7622-47b1-bb8d-26e9c1c8b9f2",
   "metadata": {},
   "source": [
    "# <font color=white><center><b>Next Word Prediction Using LSTM </center><br></font>\n",
    "This notebook demonstrates a next-word prediction model trained on text data using an LSTM-based neural network. The steps include preprocessing the text, creating input-output sequences for training, building and training the model, and evaluating it using ROUGE scores."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d7f3730-74d6-4822-97f8-5733eae95a2b",
   "metadata": {},
   "source": [
    "## Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "83650f15-8784-4255-8569-a639a626a086",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from rouge import Rouge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71690542-416d-408e-8045-8ef70a83d7ce",
   "metadata": {},
   "source": [
    "## Read the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd981540-0afc-47ea-be00-da5f2c0d879f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"The Modern Prometheus.txt\", 'r', encoding='utf-8') as file:\n",
    "    text = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307a657b-efe4-4d1f-bce3-ebca17e57af4",
   "metadata": {},
   "source": [
    "## Tokenizing the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c81252f6-49fa-42f3-94b3-870ba1267167",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "total_words = len(tokenizer.word_index) + 1 # Total vocabulary size"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b39878-54e1-4438-8b08-87b33cbc05de",
   "metadata": {},
   "source": [
    "## Creating input sequences for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "42f98405-ea16-4dab-b44d-0e430ae03b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = []\n",
    "for line in text.split('\\n'):\n",
    "    token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "    for i in range(1, len(token_list)):\n",
    "        n_gram_sequence = token_list[:i+1]\n",
    "        input_sequences.append(n_gram_sequence)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94c502e7-3199-4ffc-a34d-77cb66f3213b",
   "metadata": {},
   "source": [
    "## Padding the sequences to uniform length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6fa2ac73-e69b-439b-bd63-203ea403d7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_len = max(len(seq) for seq in input_sequences)\n",
    "input_sequences = np.array(pad_sequences(input_sequences, maxlen=max_sequence_len, padding='pre'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e42667-d0e8-457d-bff7-e8fcb831a704",
   "metadata": {},
   "source": [
    "## Splitting the data into features (X) and labels (y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "795f7a0d-e1fc-4073-a9d0-7aa5d0b5016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = input_sequences[:, :-1]\n",
    "y = input_sequences[:, -1]\n",
    "y = np.array(tf.keras.utils.to_categorical(y, num_classes=total_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d440dd90-bb39-491d-b6ec-527eec50cbb1",
   "metadata": {},
   "source": [
    "## Building and training the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ac1c3d4-56f0-49d5-b3f2-2d6865c0c145",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Embedding(total_words, 100, input_length=max_sequence_len-1))\n",
    "model.add(LSTM(150))\n",
    "model.add(Dense(total_words, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d0862d3b-ab22-433a-83ed-8b14cb49ccb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 17, 100)           760600    \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 150)               150600    \n",
      "                                                                 \n",
      " dense (Dense)               (None, 7606)              1148506   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,059,706\n",
      "Trainable params: 2,059,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3d965c01-1c15-4438-854c-c8ef0d108856",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9456f34f-f431-4dc1-b59a-78bf093f1e75",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "2243/2243 [==============================] - 30s 11ms/step - loss: 6.4433 - accuracy: 0.0795\n",
      "Epoch 2/50\n",
      "2243/2243 [==============================] - 26s 12ms/step - loss: 5.7895 - accuracy: 0.1235\n",
      "Epoch 3/50\n",
      "2243/2243 [==============================] - 26s 12ms/step - loss: 5.4094 - accuracy: 0.1488\n",
      "Epoch 4/50\n",
      "2243/2243 [==============================] - 26s 12ms/step - loss: 5.0784 - accuracy: 0.1684\n",
      "Epoch 5/50\n",
      "2243/2243 [==============================] - 26s 12ms/step - loss: 4.7599 - accuracy: 0.1867\n",
      "Epoch 6/50\n",
      "2243/2243 [==============================] - 26s 11ms/step - loss: 4.4482 - accuracy: 0.2044\n",
      "Epoch 7/50\n",
      "2243/2243 [==============================] - 26s 12ms/step - loss: 4.1437 - accuracy: 0.2270\n",
      "Epoch 8/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 3.8517 - accuracy: 0.2552\n",
      "Epoch 9/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 3.5695 - accuracy: 0.2897\n",
      "Epoch 10/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 3.3008 - accuracy: 0.3288\n",
      "Epoch 11/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 3.0499 - accuracy: 0.3708\n",
      "Epoch 12/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 2.8127 - accuracy: 0.4116\n",
      "Epoch 13/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 2.5961 - accuracy: 0.4511\n",
      "Epoch 14/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 2.3935 - accuracy: 0.4916\n",
      "Epoch 15/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 2.2064 - accuracy: 0.5285\n",
      "Epoch 16/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 2.0369 - accuracy: 0.5630\n",
      "Epoch 17/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.8773 - accuracy: 0.5972\n",
      "Epoch 18/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.7337 - accuracy: 0.6268\n",
      "Epoch 19/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.6004 - accuracy: 0.6563\n",
      "Epoch 20/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.4782 - accuracy: 0.6836\n",
      "Epoch 21/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.3679 - accuracy: 0.7072\n",
      "Epoch 22/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.2649 - accuracy: 0.7302\n",
      "Epoch 23/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.1729 - accuracy: 0.7489\n",
      "Epoch 24/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.0868 - accuracy: 0.7694\n",
      "Epoch 25/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 1.0101 - accuracy: 0.7847\n",
      "Epoch 26/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.9411 - accuracy: 0.8004\n",
      "Epoch 27/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.8793 - accuracy: 0.8131\n",
      "Epoch 28/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.8200 - accuracy: 0.8275\n",
      "Epoch 29/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.7705 - accuracy: 0.8377\n",
      "Epoch 30/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.7251 - accuracy: 0.8462\n",
      "Epoch 31/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.6809 - accuracy: 0.8571\n",
      "Epoch 32/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.6441 - accuracy: 0.8636\n",
      "Epoch 33/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.6116 - accuracy: 0.8709\n",
      "Epoch 34/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.5787 - accuracy: 0.8775\n",
      "Epoch 35/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.5538 - accuracy: 0.8830\n",
      "Epoch 36/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.5297 - accuracy: 0.8859\n",
      "Epoch 37/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.5061 - accuracy: 0.8909\n",
      "Epoch 38/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4898 - accuracy: 0.8937\n",
      "Epoch 39/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4691 - accuracy: 0.8980\n",
      "Epoch 40/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4554 - accuracy: 0.8998\n",
      "Epoch 41/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4416 - accuracy: 0.9017\n",
      "Epoch 42/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4291 - accuracy: 0.9041\n",
      "Epoch 43/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4160 - accuracy: 0.9063\n",
      "Epoch 44/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.4039 - accuracy: 0.9080\n",
      "Epoch 45/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3997 - accuracy: 0.9090\n",
      "Epoch 46/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3904 - accuracy: 0.9103\n",
      "Epoch 47/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3852 - accuracy: 0.9101\n",
      "Epoch 48/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3771 - accuracy: 0.9111\n",
      "Epoch 49/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3723 - accuracy: 0.9122\n",
      "Epoch 50/50\n",
      "2243/2243 [==============================] - 27s 12ms/step - loss: 0.3655 - accuracy: 0.9132\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1ce64843ee0>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14dc14ce-3ed3-4097-8fd9-2f09679def95",
   "metadata": {},
   "source": [
    "## Predicting the next n words for a given seed text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98ed871d-0ec9-4c9c-8c65-a2137594ed5a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 36ms/step\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "1/1 [==============================] - 0s 33ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The master is a person of an excellent disposition'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text = \"The master is\"\n",
    "next_words = 6\n",
    "\n",
    "def predict_next_n_words(seed_text, next_words):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], maxlen=max_sequence_len-1, padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list), axis=-1)\n",
    "        output_word = \"\"\n",
    "        for word, index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \" + output_word\n",
    "    return seed_text\n",
    "\n",
    "predict_next_n_words(seed_text, next_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88fbea7d-97ad-4257-ab5c-e57418afdad8",
   "metadata": {},
   "source": [
    "## Generating test data from the text file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d307765c-b852-4341-a180-265f2fda4486",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split('\\n')\n",
    "\n",
    "test_sentences = [s.strip() for s in sentences[-6:] if len(s.strip()) > 0]  # Select last 6 sentences for evaluation\n",
    "reference_sentences = [\" \".join(test_sentences[i].split()[:10]) for i in range(len(test_sentences))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3337114a-ce46-4c55-afeb-7ef42cd0fe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 17ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 18ms/step\n",
      "1/1 [==============================] - 0s 23ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['This website includes information about Project Gutenberg™, work b is the foundation',\n",
       " 'including how to make donations to the Project Gutenberg Literary archive foundation “the name of',\n",
       " 'Archive Foundation, how to help produce our new eBooks, and how to you to make the work',\n",
       " 'subscribe to our email newsletter to hear about new eBooks. in amusement to be torn']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = [predict_next_n_words(sentence, 5) for sentence in test_sentences]\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaca9840-2855-4628-a12d-b4ce807e445c",
   "metadata": {},
   "source": [
    "## Evaluating the model with ROUGE scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cf3bf3ef-1aeb-40f5-9626-d300dfa2a852",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rouge-1': {'r': 1.0, 'p': 0.6581959706959708, 'f': 0.7927414833293042},\n",
       " 'rouge-2': {'r': 1.0, 'p': 0.6077922077922078, 'f': 0.755274931365785},\n",
       " 'rouge-l': {'r': 1.0, 'p': 0.6581959706959708, 'f': 0.7927414833293042}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rouge = Rouge()\n",
    "scores = rouge.get_scores(predictions, reference_sentences, avg=True)\n",
    "\n",
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb108dca-0e60-4761-b649-ef561ec9973d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
